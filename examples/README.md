# Sprite Clothing Generator - Example Setup

This directory contains example input files and a placeholder for output files to demonstrate the sprite clothing generation pipeline.

## Contents

### Input Files

- `input/base.png` - A 5x5 test spritesheet (25 frames) with distinct colored frames
- `input/reference.png` - A test reference frame showing a simple "clothing" pattern

These are test fixtures generated by `tests/fixtures/create_test_data.py` for demonstration purposes.

## Running the Example

**IMPORTANT**: This example requires ComfyUI to be running at http://127.0.0.1:8188

### Prerequisites

1. ComfyUI server must be running:
   ```bash
   cd /Users/roberthyatt/Code/ComfyUI
   python main.py
   ```

2. Required models must be installed:
   - Checkpoint: `models/checkpoints/PixelartSpritesheet_V.1.ckpt`
   - ControlNet: `models/controlnet/control_v11p_sd15_openpose_fp16.safetensors`

3. Required custom nodes:
   - `comfyui_controlnet_aux` (OpenPose preprocessor)
   - `rembg-comfyui-node-better` (U2-Net background removal)

### Running the Example

Once ComfyUI is running, execute:

```bash
cd /Users/roberthyatt/Code/ComfyUI

python generate_sprite_clothing.py \
    --base examples/input/base.png \
    --reference examples/input/reference.png \
    --frame 12 \
    --output examples/output/clothing.png \
    --seed 42 \
    --keep-temp
```

### Expected Output

- `output/clothing.png` - A 5x5 clothing-only spritesheet matching the poses from the base
- Temporary files in `sprite_clothing_gen/temp/` (if `--keep-temp` is used):
  - `frames/` - Individual frames from the base spritesheet
  - `poses/` - OpenPose skeleton extractions
  - `clothing/` - Generated clothing layers for each frame
  - `reference_clothing_only.png` - Segmented clothing from reference

### Using Real Assets

To test with your own assets:

1. Replace `input/base.png` with your 5x5 base spritesheet (naked/base character)
2. Replace `input/reference.png` with a clothed reference frame from Ludo
3. Update the `--frame` parameter to match which frame index (0-24) your reference corresponds to
4. Run the command above

## Troubleshooting

### "ComfyUI server not accessible"

Make sure ComfyUI is running in a separate terminal:
```bash
cd /Users/roberthyatt/Code/ComfyUI
python main.py
```

Wait for the server to fully start before running the generation script.

### "Model not found"

Download the required models and place them in the correct directories:
- Checkpoint models go in `models/checkpoints/`
- ControlNet models go in `models/controlnet/`

### Generation Takes a Long Time

Generation involves processing 25 frames, each requiring:
1. OpenPose skeleton extraction
2. ControlNet-guided image generation

Expect 5-10 minutes for a complete run depending on your hardware.

## Notes

- This example uses simple test fixtures for demonstration
- Real Ludo-generated assets will produce much better results
- The test fixtures are purely geometric patterns for validation
- Generated output quality depends heavily on input quality and model weights
